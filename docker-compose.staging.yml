version: "3.9"

services:
  loki:
    image: grafana/loki:latest
    container_name: loki-staging
    ports:
      - "3100:3100"
    volumes:
      - ./loki/loki-config.yml:/etc/loki/local-config.yml:ro
      - loki-data:/loki
    command: -config.file=/etc/loki/local-config.yml
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:3100/ready",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - staging-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  promtail:
    image: grafana/promtail:latest
    container_name: promtail-staging
    volumes:
      - ./promtail/promtail-config.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: -config.file=/etc/promtail/config.yml
    restart: unless-stopped
    depends_on:
      - loki
    networks:
      - staging-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus-staging
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alert-rules.yml:/etc/prometheus/alert-rules.yml:ro
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=30d"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:9090/-/healthy",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    depends_on:
      - loki
    networks:
      - staging-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter-staging
    environment:
      DATA_SOURCE_NAME: "postgresql://${DB_USER}:${DB_PASSWORD}@postgres-staging:5432/faceless_youtube_staging?sslmode=disable"
    ports:
      - "9187:9187"
    restart: unless-stopped
    depends_on:
      - postgres-staging
    networks:
      - staging-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter-staging
    environment:
      REDIS_ADDR: "redis-staging:6379"
    ports:
      - "9121:9121"
    restart: unless-stopped
    depends_on:
      - redis-staging
    networks:
      - staging-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter-staging
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - "--path.procfs=/host/proc"
      - "--path.sysfs=/host/sys"
      - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)"
    restart: unless-stopped
    networks:
      - staging-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager-staging
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager-data:/alertmanager
    command:
      - "--config.file=/etc/alertmanager/alertmanager.yml"
      - "--storage.path=/alertmanager"
      - "--web.external-url=http://localhost:9093"
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:9093/-/healthy",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    depends_on:
      - prometheus
    networks:
      - staging-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  grafana:
    image: grafana/grafana:latest
    container_name: grafana-staging
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_PATHS_DASHBOARDS=/var/lib/grafana/dashboards
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-worldmap-panel
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana-data:/var/lib/grafana
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:3000/api/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    depends_on:
      - prometheus
      - loki
    networks:
      - staging-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  nginx:
    build:
      context: .
      dockerfile: Dockerfile.nginx
    image: faceless-youtube-nginx-waf:staging
    container_name: nginx-staging
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/modsecurity-locations.conf:/etc/nginx/modsecurity-locations.conf:ro
      - ./modsecurity/modsecurity.conf:/etc/modsecurity/modsecurity.conf:ro
      - ./modsecurity/crs-setup.conf:/etc/modsecurity/crs-setup.conf:ro
      - ./modsecurity/crs/rules:/etc/modsecurity/crs/rules:ro
      - ./modsecurity/modsecurity-custom-rules.conf:/etc/modsecurity/modsecurity-custom-rules.conf:ro
      - ./certs:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
      - /etc/modsecurity/audit.log:/var/log/modsecurity/audit.log
    environment:
      - MODSECURITY_ENV=staging
      - ALERT_MANAGER_URL=http://alertmanager-staging:9093
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    depends_on:
      - api
      - alertmanager
    networks:
      - staging-network
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  api:
    build:
      context: .
      dockerfile: Dockerfile.prod
      args:
        ENVIRONMENT: staging
    image: faceless-youtube-api:staging
    container_name: api-staging
    environment:
      - ENVIRONMENT=staging
      - DATABASE_URL=${DATABASE_URL}
      - MONGODB_URI=${MONGODB_URI}
      - REDIS_URL=${REDIS_URL}
    ports:
      - "8001:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    depends_on:
      postgres-staging:
        condition: service_started
      mongodb-staging:
        condition: service_started
      redis-staging:
        condition: service_started
    networks:
      - staging-network
    volumes:
      - ./logs:/app/logs

  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile.prod
      args:
        ENVIRONMENT: staging
    image: faceless-youtube-dashboard:staging
    container_name: dashboard-staging
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    depends_on:
      - api
    networks:
      - staging-network
    environment:
      - REACT_APP_API_URL=https://localhost

  postgres-staging:
    image: postgres:15-alpine
    container_name: postgres-staging
    environment:
      POSTGRES_DB: faceless_youtube_staging
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_INITDB_ARGS: "-c shared_preload_libraries=pgaudit"
    command:
      - "postgres"
      - "-c"
      - "pgaudit.log=ALL"
      - "-c"
      - "pgaudit.log_rows=on"
      - "-c"
      - "log_statement=all"
      - "-c"
      - "log_connections=on"
      - "-c"
      - "log_disconnections=on"
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    volumes:
      - postgres-staging-data:/var/lib/postgresql/data
      - ./pg_audit_init.sh:/docker-entrypoint-initdb.d/99-audit-init.sh:ro
    networks:
      - staging-network

  mongodb-staging:
    image: mongo:7
    container_name: mongodb-staging
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
      MONGO_INITDB_DATABASE: faceless_youtube_staging
    ports:
      - "27017:27017"
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    volumes:
      - mongodb-staging-data:/data/db
    networks:
      - staging-network

  redis-staging:
    image: redis:7-alpine
    container_name: redis-staging
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    volumes:
      - redis-staging-data:/data
    networks:
      - staging-network

  suricata-staging:
    image: jasonish/suricata:latest
    container_name: suricata-staging
    ports:
      - "9998:9998"
    cap_add:
      - NET_ADMIN
      - SYS_NICE
    volumes:
      - ./suricata/suricata.yaml:/etc/suricata/suricata.yaml:ro
      - ./suricata/rules/:/etc/suricata/rules/:ro
      - suricata-logs:/var/log/suricata
    environment:
      - SURICATA_OPTIONS=-i any
    command: -c /etc/suricata/suricata.yaml -i any
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9998/stats"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    restart: unless-stopped
    networks:
      - staging-network
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

networks:
  staging-network:
    driver: bridge

volumes:
  postgres-staging-data:
  mongodb-staging-data:
  redis-staging-data:
  loki-data:
  prometheus-data:
  alertmanager-data:
  grafana-data:
  suricata-logs:
